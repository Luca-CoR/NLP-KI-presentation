# The other papers I looked at during my research

### Citation style:

- Chicago

---

### Large Language Models Are Human-Level Prompt Engineers

[link to paper] (https://arxiv.org/abs/2211.01910)

- normal arXiv license
- used in Emotion Paper for selecting BIG-bench prompts (aka, these guys selected stuff and the Emotion Prompt people copied from here)
- cite as "Zhou, Yongchao, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. "Large language models are human-level prompt engineers." In The Eleventh International Conference on Learning Representations. 2022. https://arxiv.org/abs/2211.01910"

---

### Instruction Induction: From Few Examples to Natural Language Task Descriptions

[link to paper] (https://arxiv.org/abs/2205.10782)  
[link to git] (https://github.com/orhonovich/instruction-induction)

- CC-BY-4.0
- used in Emotion Paper for the Instruction Induction prompts they provide. They don't seem to provide the 100 examples for each prompt, which I assume is the reason why the Emotion Paper only has a limited example pool for the more advanced prompts. \[ETA: the examples are shared in the git of this paper, I have no clue why they didn't use them (or make their own)]
- cite as "Honovich, Or, Uri Shaham, Samuel R. Bowman, and Omer Levy. "Instruction induction: From few examples to natural language task descriptions." arXiv preprint arXiv:2205.10782 (2022). Licensed under CC BY 4.0. https://arxiv.org/abs/2205.10782"
